{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"13h-BrxMU9JlkZnRJPNmQoUlIgIlaRjnM","timestamp":1710945537138},{"file_id":"1visVXLl0JFQKRl_G-BkN8gp45NSfyN9A","timestamp":1710781731755}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-nVLftxNZV5H"},"source":["# Технологии машинного обучения\n","\n","## Практическая 6. Дообучение CNN\n","\n","В современных задачах обработки изображений, будь то задача обнаружения объектов, задача распознавания образов, задача (семантической) сегментации, задача классификации изображений и другие, всё чаще используют **свёрточные нейросети** (*Convolutional Neural Networks*, *CNN*).\n","\n","Они показывают очень хорошие результаты, за ними стоит как математический аппарат, так и эвристики, полученные опытным путём.\n","\n","**В данном задании** Вам предстоит познакомиться с архитектурами *AlexNet*, *VGG* и *Inception* и для каждой из этих моделей использовать технику **Transfer Learning**.  \n","\n","* **Transfer Learning** - это процесс дообучения на **новых данных** какой-либо нейросети, уже обученной до этого на других данных, обычно на каком-нибудь хорошем, большом (миллионы картинок) датасете (например, [ImageNet](http://www.image-net.org/) ~ 14 млн картинок).\n"]},{"cell_type":"markdown","source":["### Теория"],"metadata":{"id":"aVU6AUVjcV1K"}},{"cell_type":"markdown","metadata":{"id":"j-EtKIoMZV5J"},"source":["Теперь мы перейдем к тому, как можно использовать уже обученные нейросети, чтобы ускорить свою работу.\n","\n","Давайте вспомним общую архитектуру CNN:"]},{"cell_type":"markdown","metadata":{"id":"XWER66eyZV5K"},"source":["<img src=\"https://hsto.org/files/97b/c66/13d/97bc6613d18c41a3a014fdcd3bc3427c.png\">"]},{"cell_type":"markdown","metadata":{"id":"bihUjSwGZV5L"},"source":["С помощью операций *свёртки (convolution)* и *пулинга (pooling)* всё, что расположено до этапа *classification*, по сути **извлекает признаки из объектов, подающихся на вход** (картинок, в данном случае). То есть вместо того, чтобы самим пытаться как-то описать картинки для хорошей работы классификатора, мы предоставляем заняться этим нейросети (обучая её методом обратного распространения ошибки."]},{"cell_type":"markdown","metadata":{"id":"H5JCuydFZV5O"},"source":["#### Описание метода\n","Представим теперь, что eсть свой набор данных, и Вы хотите научить сеть классифицировать объекты из Вашей выборки.  \n","Есть 4 возможных подхода к задаче:\n","\n","* **1. Написать свою собственную нейронную сеть**\n","    * Если Вас зовут не [Ian Godfellow](https://en.wikipedia.org/wiki/Ian_Goodfellow), [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) или [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng), то не рекомендуется пользоваться этим способом\n","    * M**ay** the **f**orce be with You\n","\n","* **2. CNN как средство для извлечения признаков (Feature Extractor)**\n","    * Берём сетку, обученную на ImageNet\n","    * Убираем последние Fully-Connected слои сети, отвечающие за классификацию. Веса предыдущих слоёв **заморожены**, мы их не трогаем. Теперь сеть выдаёт не метки классов, а то, что поступало на вход Fully-Connected (развёрнутый в строку \"параллелепипед\" HxWxNUM_FILTERS с последнего слоя перед FC)\n","    * Запускаем сеть на новом датасете, получаем выходы сети для всех объектов - это и есть их признаки, полученные сетью\n","    * Обучаем на этих признаках какой-либо классификатор (свою Fully-Connected сеть, например)\n","    * Теперь у нас есть сеть, работающая хорошо на нашем датасете\n","\n","* **3. CNN, которую можно дообучить (Fine Tuning)**  \n","    * Берём сетку, обученную на ImageNet  \n","    * Убираем последние Fully-Connected слои сети, отвечающие за классификацию.  \n","    * Теперь всё же *распространяем backpropagation ещё на сколько-то слоёв назад (размораживаем веса в этих слоях)*, чтобы скорректировать их под новые данные. Можно распространить обучение и на всю сеть, но часто первые слои всё же замораживают, поскольку они (как ожидается) извлекают более общие признаки. А ещё обучать всю сеть всё же дольше, чем несколько слоёв. Всё зависит от того, какого качества Вы хотите добиться\n","    * Теперь сеть выдаёт не метки классов, а то, что поступало на вход Fully-Connected (веса последних (или всех) слоёв были изменены под наши данные)\n","    * Обучаем на этих признаках какой-либо классификатор (свою Fully-Connected сеть, например)\n","    * Теперь у нас есть сеть, работающая хорошо на нашем датасете\n","\n","* **4. Использовать предобученную модель \"из коробки\"**  \n","    * То есть взять уже готовую нейронную сеть и использовать её (её параметры (W, b..), ведь сеть характеризуется параметрами, если архитектура известна) для решения своей задачи. Например, [здесь](https://github.com/BVLC/caffe/wiki/Model-Zoo) люди часто выкладывают веса моделей, обученных для решения их специфических задач.  \n","\n","\n","В зависимости от количества и природы Ваших данных есть выбор из **нескольких стратегий Transfer Learning**, а именно:\n","\n","* *У Вас **мало данных** ($\\le$ 10k), и они **похожи** на данные, на которых была обучена сеть до этого*  \n","Если данные совсем похожи, можно попробовать использовать готовую модель. Если качество Вас не устраивает, то тогда стоит использовать CNN для извлечения признаков и обучить свой классификатор на этих данных (2-ой способ выше). Так как данные похожи на те, на которых обучалась сеть, то высокоуровневые признаки, полученные с помощью последних слоёв сети, должны оказаться информативными. Если делать в этом случае Fine-Tuning (3 способ), то сеть может переобучиться, поскольку данных мало.\n","* *У Вас **мало данных** ($\\le$ 10k), и они **не похожи** на данные, на которых была обучена сеть до этого*  \n","Самый невыгодный случай. Здесь мы не можем ожидать от сети, что выходы последних слоёв будут информативными для новых данных. Следует также действовать в соответствие со 2-ым способом, но брать как признаки выходы более ранних слоёв, ведь, как мы помним, они (как ожидается) соответствуют более общим паттернам в данных.\n","* *У Вас **много данных** ($\\ge$ 10k), и они **похожи** на данные, на которых была обучена сеть до этого*  \n","В этом случае можем смело делать Fine-Tuning (3 способ) (если не устроило качество модели \"из коробки\"), ведь данных много, и вероятность переобучения меньше. В данном случае имеет смысл попробовать разморохить веса последних нескольких слоёв (зависит от того, сколько у Вас времени и вычислительной мощности, можно разморозить и всю сеть)\n","* *У Вас **много данных** ($\\ge$ 10k), и они **не похожи** на данные, на которых была обучена сеть до этого*\n","В принципе, подход тот же, что и в случае похожих данных, то есть мы файнтюним практически всю нейросеть. Однако мы вольны в этом случае полнстью менять все параметры (и гиперпараметры) нейросети, ведь по сути мы пользуемся только её архитектурой, забывая о том, что она уже была когда-то обучена. Но часто веса предобученной сети оставляют в качестве инициализации для обучения на новых данных.\n","\n","Надеемся, что теперь Вам стало понятнее, как обучать крутые сети на новых данных."]},{"cell_type":"markdown","source":["### Оценивание и штрафы"],"metadata":{"id":"wkTPRLJ_cRPq"}},{"cell_type":"markdown","source":["Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). **Также**, в этой практической работе баллы начисляются и за ответы на вопросы. Максимально допустимая оценка за работу — 10 баллов."],"metadata":{"id":"ItqUYPd0IJqv"}},{"cell_type":"markdown","metadata":{"id":"weT3x9DQZV5X"},"source":["### О задании"]},{"cell_type":"markdown","metadata":{"id":"F8paFz_5ZV5Y"},"source":["Вам предстоит попробовать использовать три типа архитектур свёрточных нейросетей\n","\n","Для каждой из следующих нейросетей:\n","* **AlexNet** (уже сделано в примере)\n","* **VGG16**\n","* **Inception_v3**\n","\n","Напишите код и выведите результат (график лосса, accuracy и вывод примера классификации картинок с визуализацией (с помощью функции `vizualize_model()`)) для трёх способов:\n","* Использование нейросети как **Feature Extractor**\n","* **Fine Tuning** нейросети\n","* **Смешанный способ** (по желанию, кроме AlexNet)\n","\n","Для каждого пункта нужно:\n","* вывести график loss'а на обучающей и на валидационной выборке\n","* вывести качество модели (accuracy) на валидационной (тестовой) выборке\n","* использовать функцию visualize_model()"]},{"cell_type":"markdown","metadata":{"id":"99LAkQNVZV5Y"},"source":["#### Данные  \n","\n","В данном задании используются сети (из библиотеки **torchvision**), предобученные на датасете ImageNet.  \n","В качестве новых данных будет датасет Меравьи vs Пчёлы, Вам нужно скачать его отсюда: **[Муравьи vs Пчёлы](https://download.pytorch.org/tutorial/hymenoptera_data.zip)**, *являющийся частью датасета ImageNet*. В нём 400 картинок, ~250 обучение и ~150 валидация (тест)."]},{"cell_type":"code","source":["!pip install torch~=1.13.1 torchvision~=0.14.1 matplotlib~=3.5.3 numpy~=1.22.4"],"metadata":{"id":"n71FAcDyT5SQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8498ab96-9478-4b89-a95d-5a9d76b967c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch~=1.13.1\n","  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m203.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision~=0.14.1\n","  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/24.2 MB\u001b[0m \u001b[31m245.6 kB/s\u001b[0m eta \u001b[36m0:00:44\u001b[0m"]}]},{"cell_type":"markdown","metadata":{"id":"8gGQA6CbZV5Z"},"source":["### Функции для отрисовки и обучения модели:"]},{"cell_type":"code","source":["import os\n","from tqdm.autonotebook import tqdm, trange\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.autograd import Variable\n","\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time"],"metadata":{"id":"YOj2-SN2VogN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LnoL3STNZV5a"},"source":["Загрузим данные:"]},{"cell_type":"code","metadata":{"id":"s3ODqjvFIY9n"},"source":["!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n","!unzip hymenoptera_data.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lKZZSUYZV5b"},"source":["# Преобразование обучающих данных для расширения обучающей выборки и её нормализация\n","# Для валидационной (тестовой) выборки только нормализация\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(244),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(244),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","# папка с данными\n","data_dir = './hymenoptera_data'\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","# специальный класс для загрузки данных в виде батчей\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                              shuffle=True, num_workers=2)\n","               for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n","\n","use_gpu = torch.cuda.is_available()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"03FqarW9ZV5e"},"source":["Размеры обучающей и валидационной выборок:"]},{"cell_type":"code","metadata":{"id":"MxjRd-5OZV5f"},"source":["print(dataset_sizes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vx3QiNAcZV5k"},"source":["**Вопрос 1 (0.5 балла):**  \n","1. В DataLoader() выше стоит \"shuffle=True\". Для чего это нужно?\n","2. Сколько картинок будет в каждом батче?"]},{"cell_type":"markdown","metadata":{"id":"IZPe4pfoZV5l"},"source":["**Ответ:** <Ваш ответ>"]},{"cell_type":"markdown","metadata":{"id":"GXqEVA1ZZV5m"},"source":["Посмотрим на картинки из датасета:"]},{"cell_type":"code","metadata":{"id":"wQG2_RrvZV5n"},"source":["def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.figure(figsize=(15, 12))\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)\n","\n","\n","# Получим 1 батч (картнки-метки) из обучающей выборки\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","# Расположим картинки рядом\n","out = torchvision.utils.make_grid(inputs)\n","\n","imshow(out, title=[class_names[x] for x in classes])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqOOeBFpZV6T"},"source":["for i in dataloaders['train']:\n","    print(i[0][0])\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6exRIPRbSgzS"},"source":["#### Обучение моделей"]},{"cell_type":"markdown","metadata":{"id":"UzP9AdAwZV5s"},"source":["Следующая функция будет использоваться для обучения модели. Аргументы:  \n","* model $-$ нейросеть\n","* loss $-$ оптимизируемая функция (criterion, cost function, objective)\n","* optimizer $-$ оптимизационный алгоритм\n","* scheduler $-$ политика изменения learning_rate\n","* num_epochs $-$ количество итераций обучения"]},{"cell_type":"markdown","metadata":{"id":"Q6kaT01UZV5u"},"source":["**Задание 1 (1 балла)**: Вам нужно модифицировать эту функцию, чтобы она возвращала ещё и массивы loss'а на обучающей и валидационной выборках (чтобы потом Вы могли нарисовать графики). Можете модифицировать эту функцию как угодно, лишь бы она правильно работала."]},{"cell_type":"code","metadata":{"id":"yGD0lrIaZV5u"},"source":["def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = model.state_dict()\n","    best_acc = 0.0\n","\n","    # YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿\n","\n","    pbar = trange(num_epochs, desc=\"Epoch:\")\n","\n","    for epoch in pbar:\n","\n","        # каждя эпоха имеет обучающую и тестовую стадии\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                scheduler.step()\n","                model.train(True)  # установить модель в режим обучения\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # итерируемся по батчам\n","            for data in tqdm(dataloaders[phase], leave=False, desc=f\"{phase} iter:\"):\n","                # получаем картинки и метки\n","                inputs, labels = data\n","\n","                # оборачиваем в переменные\n","                if use_gpu:\n","                    inputs = inputs.cuda()\n","                    labels = labels.cuda()\n","                else:\n","                    inputs, labels = inputs, labels\n","\n","                # инициализируем градиенты параметров\n","                if phase==\"train\":\n","                    optimizer.zero_grad()\n","\n","                # forward pass\n","                if phase == \"eval\":\n","                    with torch.no_grad():\n","                        outputs = model(inputs)\n","                else:\n","                    outputs = model(inputs)\n","                preds = torch.argmax(outputs, -1)\n","                loss = criterion(outputs, labels)\n","\n","                # backward pass + оптимизируем только если это стадия обучения\n","                if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                # статистика\n","                running_loss += loss.item()\n","                running_corrects += int(torch.sum(preds == labels.data))\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects / dataset_sizes[phase]\n","\n","            # YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿\n","\n","            pbar.set_description('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                                    phase, epoch_loss, epoch_acc\n","                                ))\n","\n","            # если достиглось лучшее качество, то запомним веса модели\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = model.state_dict()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # загрузим лучшие веса модели\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7VsQHae5ZV5x"},"source":["Функция для отрисовки тестовых изображений и предсказаний для них:"]},{"cell_type":"code","metadata":{"id":"Pyth5M_FZV5y"},"source":["def visualize_model(model, num_images=6):\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    for i, data in enumerate(dataloaders['val']):\n","        inputs, labels = data\n","        if use_gpu:\n","            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n","        else:\n","            inputs, labels = Variable(inputs), Variable(labels)\n","\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        for j in range(inputs.size()[0]):\n","            images_so_far += 1\n","            ax = plt.subplot(num_images // 2, 2, images_so_far)\n","            ax.axis('off')\n","            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n","            imshow(inputs.cpu().data[j])\n","\n","            if images_so_far == num_images:\n","                return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6G4XJbmSgz_"},"source":["Функция для измерения точности модели на валидационном датасете"]},{"cell_type":"code","metadata":{"id":"qAzhvxyASg0F"},"source":["def evaluate(model):\n","    model.eval()\n","\n","    runninig_correct = 0\n","    for data in dataloaders['val']:\n","        # получаем картинки и метки\n","        inputs, labels = data\n","\n","        # переносим на gpu, если возможно\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","\n","        # forward pass\n","        output = model(inputs)\n","        _, predicted = torch.max(output, 1)\n","\n","        runninig_correct += int(torch.sum(predicted == labels))\n","\n","    return runninig_correct / dataset_sizes['val']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8XzWmgE7ZV54"},"source":["### AlexNet"]},{"cell_type":"markdown","metadata":{"id":"ftbL13LPcWIt"},"source":["**AlexNet** - нейронная сеть, которая победила в ILSVRC (соревнование по классификации картинок из ImageNet) в 2012 году и стала основой для многих других архитектур. Впервые она была представлена в статье  “ImageNet Classification with Deep Convolutional Neural Networks”, над которой работал Джоффри Хинтон - человек, которого многие называют отцом современного computer vision.\n","\n","Архитектура описана на картинке ниже"]},{"cell_type":"markdown","metadata":{"id":"fk44Uh1ociVA"},"source":["<img src=\"https://www.learnopencv.com/wp-content/uploads/2018/05/AlexNet-1.png\">"]},{"cell_type":"markdown","metadata":{"id":"B6u4GAgKcqOJ"},"source":["**AlexNet** состоит из 5 **сверточных** слоев, 3 **MaxPool** слоев и 2 **FullyConnected** слоев в конце. Обратите внимание, что в последнем пулинг слое окна, из которых берется максимум, пересекаются за счет того, что *stride*=2. Это изменение по сравнению с традиционным пулингом помогло снизить ошибку на 0.4%.\n","\n","По сути **AlexNet** это самая базовая архитектура для сверточной сети после LeNet, которую мы уже писали на предыдущем занятии."]},{"cell_type":"markdown","metadata":{"id":"g6zW24cSZV56"},"source":["*ПРИМЕЧАНИЕ: Здесь не выведены графики loss'а и не использована visualize_model(). Это ожидается от Вас*"]},{"cell_type":"markdown","metadata":{"id":"FmLx0a_uZV56"},"source":["Загрузка модели:"]},{"cell_type":"code","metadata":{"id":"1mHbrvXAZV57"},"source":["model = models.alexnet(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W_g9XqLsZV5-"},"source":["Посмотрим, что внутри:"]},{"cell_type":"code","metadata":{"id":"N-OLqslsZV6A"},"source":["model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O9LYMESWZV6E"},"source":["Видим, что на вход классификатору (classifier) подаётся *9216 признаков*. Это и будет размер входа для нашего нового классификатора."]},{"cell_type":"markdown","metadata":{"id":"FA5qB523ZV6G"},"source":["####Fine Tuning способ:"]},{"cell_type":"markdown","metadata":{"id":"AxucpA3FZV6H"},"source":["Сконфигурируем - изменим FC-слой и зададим *cost function* и *оптимизирующий алгоритм*:"]},{"cell_type":"markdown","metadata":{"id":"6JKPZYgVZV6J"},"source":["(*по умолчанию backpropagation распространяется на все слои, поэтому здесь мы только заменяем FC-слой на свой классификатор*)"]},{"cell_type":"code","metadata":{"id":"ppIGmkz4ZV6K"},"source":["# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n","num_features = 9216\n","# Заменяем Fully-Connected слой на наш линейный классификатор\n","model.classifier = nn.Linear(num_features, 2)\n","\n","# Использовать ли GPU\n","if use_gpu:\n","    model = model.cuda()\n","\n","# В качестве cost function используем кросс-энтропию\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# В качестве оптимизатора - стохастический градиентный спуск\n","optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Умножает learning_rate на 0.1 каждые 7 эпох (это одна из эвристик, не было на лекциях)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXDZK7JVZV6X","scrolled":true},"source":["model, losses = train_model(model, loss_fn, optimizer_ft, exp_lr_scheduler, num_epochs=25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Задание 2 (0.5 балла)**:\n","* вывести график loss'а на обучающей и на валидационной выборке\n","* вывести качество модели (accuracy) на валидационной (тестовой) выборке\n","* использовать функцию visualize_model()"],"metadata":{"id":"AsEjWOELNEpv"}},{"cell_type":"code","metadata":{"id":"_MsDT40aSg1n"},"source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vyM6SLNZZV6g"},"source":["####Feature Extractor способ:"]},{"cell_type":"code","metadata":{"id":"81XVFTJiZV6h"},"source":["model_extractor = models.alexnet(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6XUzgLSlZV6m"},"source":["Помним, что по-умолчанию все слои нейросети обучаются заново:"]},{"cell_type":"code","metadata":{"id":"8kiGUDNqZV6n"},"source":["for param in model_extractor.parameters():\n","    print(param.requires_grad)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOTXa28JZV6s"},"source":["Сделаем так, чтобы на них *не распространялся backpropagation* (заморозим их), и подменим классификатор (ведь старый уже с весами для ImageNet'а)."]},{"cell_type":"code","metadata":{"id":"K7rW4vKaZV6u"},"source":["# замораживаем параметры (веса)\n","for param in model_extractor.parameters():\n","    param.requires_grad = False\n","\n","# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n","num_features = 9216\n","# Заменяем Fully-Connected слой на наш линейный классификатор\n","model_extractor.classifier = nn.Linear(num_features, 2)\n","\n","# Использовать ли GPU\n","if use_gpu:\n","    model_extractor = model_extractor.cuda()\n","\n","# В качестве cost function используем кросс-энтропию\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Обучаем только классификатор\n","optimizer = optim.Adam(model_extractor.classifier.parameters(), lr=1e-4)\n","\n","# Умножает learning_rate на 0.1 каждые 7 эпох (это одна из эвристик, не было на лекциях)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVL7TjRIZV6z"},"source":["%%time\n","model_extractor,losses = train_model(model_extractor, loss_fn, optimizer, exp_lr_scheduler, num_epochs=25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Задание 3 (0.5 балла)**:\n","* вывести график loss'а на обучающей и на валидационной выборке\n","* вывести качество модели (accuracy) на валидационной (тестовой) выборке\n","* использовать функцию visualize_model()"],"metadata":{"id":"5YI-2Fu_P15U"}},{"cell_type":"code","source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"metadata":{"id":"kjqTH0dPROVH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RmehLHv9Sg3d"},"source":["#### Смешанный способ:\n","Мы будем обучать не только последний **fully connected** слой, но и несколько предпоследних"]},{"cell_type":"code","metadata":{"id":"NAcI23-OSg3e"},"source":["model_mixed = models.alexnet(pretrained=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TG7n2z9bSg3h"},"source":["layers_to_unfreeze = 5\n","\n","# Выключаем подсчет градиентов для слоев, которые не будем обучать\n","for param in model_mixed.features[:-layers_to_unfreeze].parameters():\n","    param.requires_grad = False\n","\n","# num_features -- это размерность вектора фич, поступающего на вход FC-слою\n","num_features = 9216\n","# Заменяем Fully-Connected слой на наш линейный классификатор\n","model_mixed.classifier = nn.Linear(num_features, 2)\n","\n","# Использовать ли GPU\n","if use_gpu:\n","    model_mixed = model_mixed.cuda()\n","\n","# В качестве cost function используем кросс-энтропию\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Обучаем последние layers_to_unfreeze слоев из сверточной части и fully connected слой\n","# parameters() возвращает просто список тензоров парамтеров, поэтому два таких списка можно сложить\n","optimizer = optim.Adam(list(model_mixed.features.parameters())[-layers_to_unfreeze:] +\n","                      list(model_mixed.classifier.parameters()), lr=1e-4)\n","\n","# Умножает learning_rate на 0.1 каждые 7 эпох (это одна из эвристик, не было на лекциях)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"908lTwBoSg3n"},"source":["%%time\n","_, losses = train_model(model_mixed, loss_fn, optimizer, exp_lr_scheduler, num_epochs=25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Задание 4 (0.5 балла)**:\n","* вывести график loss'а на обучающей и на валидационной выборке\n","* вывести качество модели (accuracy) на валидационной (тестовой) выборке\n","* использовать функцию visualize_model()"],"metadata":{"id":"Xp32uM47Rk44"}},{"cell_type":"code","source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"metadata":{"id":"3zGeB7eGRsP9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ue3eslBDZV67"},"source":["**Вопрос 2 (0.5 балла):** С чем связано повышение качества если мы перестаем учить всю сеть? (Подсказка: посмотрите на датасет и на то, как он согласуется с 4-мя ситуациями, описанными выше)"]},{"cell_type":"markdown","metadata":{"id":"Zz5G8Z2IZV69"},"source":["**Ответ** <Ваш ответ>"]},{"cell_type":"markdown","metadata":{"id":"aXmlLczGSg4l"},"source":["**Вопрос 3 (0.5 балла)**: Почему разморозка последних слоев не дает прироста к точности, хотя разморозить несколько послдних слоев обычно хорошеее решение для классификации похожего датасета?"]},{"cell_type":"markdown","metadata":{"id":"bA2MxfZfSg4q"},"source":["**Ответ:** <Ваш ответ>"]},{"cell_type":"markdown","source":["### VGG16"],"metadata":{"id":"LGaRyrE7TSC5"}},{"cell_type":"markdown","metadata":{"id":"YLb_VQ-nZV7Y"},"source":["Один **сверточный** слой с фильтром 5$\\times$5 можно заменить двумя подряд идущими слоями с фильтрами размером 3$\\times$3, так как **воспринимаемая область** картинки у них будет одинаковой. При этом уменьшиться количество параметров, поэтому такую сеть будет легче обучать.\n","\n","На момент создания VGG люди уже заметили, что чем больше слоев в нейросети, тем выше ее точность. Заменяя большие фильтры на несколько фильтров 3$\\times$3 исследователи получили глубокую нейросеть с меньшим количеством параметров. Архитектура VGG-16 (версии VGG с 16 слоями) представлена на картинке ниже:\n","\n","<img src=\"https://cdn-images-1.medium.com/max/1040/1*0Tk4JclhGOCR_uLe6RKvUQ.png\">\n","\n","Когда говорят **VGG**, то чаще всего имеют ввиду **VGG-16** или **VGG-19**. Более глубоких версий **VGG** нет, так как после 19 слоев точность начинает падать.\n","\n","Чтобы добиться высоких результатов в соревновании при обучении и валидации нейросети использовались дополнительные приемы, подробнее о которых можно прочитать в [статье на Medium](https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11)."]},{"cell_type":"markdown","source":["####Fine Tuning способ **(1 балл)**:"],"metadata":{"id":"ZLuzzMM3Xr2o"}},{"cell_type":"code","source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"metadata":{"id":"CT2Z2OVcYBeN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Feature Extractor способ **(1 балл)**:"],"metadata":{"id":"ImWHoZ-bYDGa"}},{"cell_type":"code","source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"metadata":{"id":"M6-E1OldYQaR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Смешанный способ:"],"metadata":{"id":"fkyrt5Q6YSbB"}},{"cell_type":"code","source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"metadata":{"id":"NK0Yc20cYTXh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inception_v3"],"metadata":{"id":"Kade9zESTdQg"}},{"cell_type":"markdown","metadata":{"id":"lw96OH0SZV7b"},"source":["Рассмотрим идею, которая подтолкнула исследователей к созданию этой архитектуры.\n","Площадь, которую занимает классифицируемый объект, может очень сильно отличаться. Пример на картинке ниже:\n","\n","<img src=\"https://cdn-images-1.medium.com/max/1040/1*aBdPBGAeta-_AM4aEyqeTQ.jpeg\">\n","\n","\n","* Для извлечения информации с большой площади лучше всего подходят **большие** фильтры, и наоборот для маленьких объектов лучше **маленькие** фильтры.\n","* Глубокие нейронные сети намного сложнее обучать: в них появляется проблема **затухания градиента** и они **переобучаются**.\n","Чтобы решить первую проблему исследователи придумали **Incepton** модуль, который применяет фильтры разного размера и затем склеивает полученные каналы. При этом извлекается как информация из больших объектов, так и из маленьких. Простейшая реализация модуля выглядит так:\n","<img src=\"https://cdn-images-1.medium.com/max/1040/1*DKjGRDd_lJeUfVlY50ojOA.png\">\n","\n","Реализацию можно сделать более эффективной, если сначала уменьшить количество каналов с помощью **сверточного слоя** 1$\\times$1 и лишь затем применить **слой** с фильтрами 5$\\times$5. Сокращение вычислений происходит за счет того, что мы сначала **уменьшаем размерность** данных и лишь затем преобразовываем их. Продвинутая реализация:\n","<img src=\"https://cdn-images-1.medium.com/max/1040/1*U_McJnp7Fnif-lw9iIC5Bw.png\">\n","\n","Сеть состоит из **корня** (нескольких сверточных слоев) и **Inception** модулей идущих за ним. Оранжевым прямоугольников выделен корень, а фиолетовыми - **вспомогательные классификаторы**. Именно они помогают бороться со второй проблемой, которую мы упомянули ранее. Наша функция потерь - взвешенная сумма **LogLoss** на двух **вспомогательных классификаторах** и **основном** в конце нейронной сети.\n","<img src=\"https://cdn-images-1.medium.com/max/1040/1*uW81y16b-ptBDV8SIT1beQ.png\">\n","\n","После Inception v1 были представлены 2, 3 и 4 версии, пррочитать о которых вы можете  в [статье на Medium](https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202)."]},{"cell_type":"code","metadata":{"id":"P3hcfum_Sg5R"},"source":["# Нужно поменять размер картинок на 299, иначе будет ошибка, так как размерность станет отрицательной.\n","# Это вызвано тем, что нейросеть изначально обучалась на картинках размера 299.\n","\n","# Результирующий размер картинок определяется трансформациями\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(299),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(299),\n","        transforms.CenterCrop(299),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# Сам объект датасета\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","\n","# специальный класс для загрузки данных в виде батчей\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                              shuffle=True, num_workers=2)\n","               for x in ['train', 'val']}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Fine Tuning способ **(1 балл)**:"],"metadata":{"id":"pgESFpi5Y-uS"}},{"cell_type":"code","source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"metadata":{"id":"2PNVcTX5Y-uT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Feature Extractor способ **(1 балл)**:"],"metadata":{"id":"GC_DI4P1ZGR_"}},{"cell_type":"code","source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"metadata":{"id":"3mrSn8hpZGR_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Смешанный способ:"],"metadata":{"id":"0__inzJRZKnN"}},{"cell_type":"code","source":["# YOUR CODE HERE ‿︵‿︵ヽ(°□° )ノ︵‿︵‿"],"metadata":{"id":"eVjTs58kZKnO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Финал0чка:"],"metadata":{"id":"Xa6BpvgScEsp"}},{"cell_type":"markdown","metadata":{"id":"DK1TsMVZZV7h"},"source":["**Вопрос 4 (2 балла):** Какая из сетей оказалась наилучшей? Как думаете, почему?"]},{"cell_type":"markdown","metadata":{"id":"sRukNGePZV7j"},"source":["**Ответ:** <Ваш ответ>"]}]}